{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-3a39350e54e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstring\u001b[0m \u001b[0;31m#additional tools to manipulate strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m \u001b[0;31m# for text manipulation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDeprecationWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "import re # for regular expressions\n",
    "import pandas as pd \n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import string #additional tools to manipulate strings\n",
    "import nltk # for text manipulation\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'fr_core_news_sm'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8f50ed8caa79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fr_core_news_sm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/spacy/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdepr_path\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW001\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepr_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDeprecationWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"exists\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Path or Path-like to model data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [E050] Can't find model 'fr_core_news_sm'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "sp = spacy.load('fr_core_news_sm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = sp(u\" Le samedi matin, mon père qui est très sportif fait de la natation, et ma mère fait la cuisine parce que chaque samedi, mes parents invitent ma tante à dîner avec nous. Enfin, le dimanche d'habitude nous ne faisons pas grand-chose; quelques fois, mon père fait du bricolage si nécessaire.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Le\n",
      "samedi\n",
      "matin\n",
      ",\n",
      "mon\n",
      "père\n",
      "qui\n",
      "est\n",
      "très\n",
      "sportif\n",
      "fait\n",
      "de\n",
      "la\n",
      "natation\n",
      ",\n",
      "et\n",
      "ma\n",
      "mère\n",
      "fait\n",
      "la\n",
      "cuisine\n",
      "parce\n",
      "que\n",
      "chaque\n",
      "samedi\n",
      ",\n",
      "mes\n",
      "parents\n",
      "invitent\n",
      "ma\n",
      "tante\n",
      "à\n",
      "dîner\n",
      "avec\n",
      "nous\n",
      ".\n",
      "Enfin\n",
      ",\n",
      "le\n",
      "dimanche\n",
      "d'\n",
      "habitude\n",
      "nous\n",
      "ne\n",
      "faisons\n",
      "pas\n",
      "grand-chose\n",
      ";\n",
      "quelques\n",
      "fois\n",
      ",\n",
      "mon\n",
      "père\n",
      "fait\n",
      "du\n",
      "bricolage\n",
      "si\n",
      "nécessaire\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for word in sentence:\n",
    "    print(word.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \n",
      "Le le\n",
      "samedi samedi\n",
      "matin matin\n",
      ", ,\n",
      "mon mon\n",
      "père père\n",
      "qui qui\n",
      "est être\n",
      "très très\n",
      "sportif sportif\n",
      "fait faire\n",
      "de de\n",
      "la le\n",
      "natation natation\n",
      ", ,\n",
      "et et\n",
      "ma mon\n",
      "mère mère\n",
      "fait faire\n",
      "la le\n",
      "cuisine cuisine\n",
      "parce parce\n",
      "que que\n",
      "chaque chaque\n",
      "samedi samedi\n",
      ", ,\n",
      "mes mon\n",
      "parents parent\n",
      "invitent inviter\n",
      "ma mon\n",
      "tante tante\n",
      "à à\n",
      "dîner dîner\n",
      "avec avec\n",
      "nous nous\n",
      ". .\n",
      "Enfin enfin\n",
      ", ,\n",
      "le le\n",
      "dimanche dimanche\n",
      "d' de\n",
      "habitude habitude\n",
      "nous nous\n",
      "ne ne\n",
      "faisons faire\n",
      "pas pas\n",
      "grand-chose grand-chose\n",
      "; ;\n",
      "quelques quelque\n",
      "fois fois\n",
      ", ,\n",
      "mon mon\n",
      "père père\n",
      "fait faire\n",
      "du de\n",
      "bricolage bricolage\n",
      "si si\n",
      "nécessaire nécessaire\n",
      ". .\n"
     ]
    }
   ],
   "source": [
    "for word in sentence:\n",
    "    print(word.text,  word.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Desktop\\NLP Project New\n"
     ]
    }
   ],
   "source": [
    "%cd C:\\Users\\HP\\Desktop\\NLP Project New\n",
    "train  = pd.read_csv('NewTweets.csv',engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>,- Tu es si adorable! Où as-tu eu cette chemise?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>,Oui, il est vraiment très lol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>,- Thé vert, une boisson pour me faire plaisir.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>,Je parlais de ne pas savoir comment épeler un mot et mal orthographié un tas! Oops! Parlez-en!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>,Hey quoi de neuf et d'accueil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment  \\\n",
       "0  POSITIVE   \n",
       "1  POSITIVE   \n",
       "2  POSITIVE   \n",
       "3  POSITIVE   \n",
       "4  POSITIVE   \n",
       "\n",
       "                                                                                        tweet_text  \n",
       "0                                                 ,- Tu es si adorable! Où as-tu eu cette chemise?  \n",
       "1                                                                   ,Oui, il est vraiment très lol  \n",
       "2                                                  ,- Thé vert, une boisson pour me faire plaisir.  \n",
       "3  ,Je parlais de ne pas savoir comment épeler un mot et mal orthographié un tas! Oops! Parlez-en!  \n",
       "4                                                                   ,Hey quoi de neuf et d'accueil  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "POSITIVE    5000\n",
       "NEGATIVE    5000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       10\n",
       "1        6\n",
       "2        9\n",
       "3       17\n",
       "4        6\n",
       "        ..\n",
       "9995    27\n",
       "9996    17\n",
       "9997    12\n",
       "9998    22\n",
       "9999     2\n",
       "Name: tweet_text, Length: 10000, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = train['tweet_text'].str.split().str.len()\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:3: MatplotlibDeprecationWarning: \n",
      "The 'normed' kwarg was deprecated in Matplotlib 2.1 and will be removed in 3.1. Use 'density' instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = \"serif\"\n",
    "plt.hist(count, bins=100, normed=False,color='0.6')\n",
    "csfont = {'fontname':'Serif'}\n",
    "plt.xlabel('Length of Tweets (in words)',**csfont)\n",
    "plt.ylabel('Number of Tweets',**csfont)\n",
    "\n",
    "plt.title('Lengths of Tweets for the French Dataset',**csfont)\n",
    "\n",
    "plt.savefig('filename.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "plt.rcParams['font.family'] = \"serif\"\n",
    "sns.distplot(count,color='0.6',hist=False)\n",
    "csfont = {'fontname':'Serif'}\n",
    "plt.xlabel('Length of Tweets (in words)',**csfont)\n",
    "plt.ylabel('Probability Density',**csfont)\n",
    "\n",
    "plt.title('Distribution Plot for Tweet Lengths of the French Dataset',**csfont)\n",
    "\n",
    "plt.savefig('filename.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Count'] = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"FrenchwCount.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to remove any pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pattern(input_txt, pattern):\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    for i in r:\n",
    "        input_txt = re.sub(i, '', input_txt)\n",
    "        \n",
    "    return input_txt    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing User Handles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tidy_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>,- Tu es si adorable! Où as-tu eu cette chemise?</td>\n",
       "      <td>,- Tu es si adorable! Où as-tu eu cette chemise?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>,Oui, il est vraiment très lol</td>\n",
       "      <td>,Oui, il est vraiment très lol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>,- Thé vert, une boisson pour me faire plaisir.</td>\n",
       "      <td>,- Thé vert, une boisson pour me faire plaisir.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>,Je parlais de ne pas savoir comment épeler un mot et mal orthographié un tas! Oops! Parlez-en!</td>\n",
       "      <td>,Je parlais de ne pas savoir comment épeler un mot et mal orthographié un tas! Oops! Parlez-en!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>,Hey quoi de neuf et d'accueil</td>\n",
       "      <td>,Hey quoi de neuf et d'accueil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment  \\\n",
       "0  POSITIVE   \n",
       "1  POSITIVE   \n",
       "2  POSITIVE   \n",
       "3  POSITIVE   \n",
       "4  POSITIVE   \n",
       "\n",
       "                                                                                        tweet_text  \\\n",
       "0                                                 ,- Tu es si adorable! Où as-tu eu cette chemise?   \n",
       "1                                                                   ,Oui, il est vraiment très lol   \n",
       "2                                                  ,- Thé vert, une boisson pour me faire plaisir.   \n",
       "3  ,Je parlais de ne pas savoir comment épeler un mot et mal orthographié un tas! Oops! Parlez-en!   \n",
       "4                                                                   ,Hey quoi de neuf et d'accueil   \n",
       "\n",
       "                                                                                        tidy_tweet  \n",
       "0                                                 ,- Tu es si adorable! Où as-tu eu cette chemise?  \n",
       "1                                                                   ,Oui, il est vraiment très lol  \n",
       "2                                                  ,- Thé vert, une boisson pour me faire plaisir.  \n",
       "3  ,Je parlais de ne pas savoir comment épeler un mot et mal orthographié un tas! Oops! Parlez-en!  \n",
       "4                                                                   ,Hey quoi de neuf et d'accueil  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['tidy_tweet'] = np.vectorize(remove_pattern)(train['tweet_text'], \"@[\\w]*\") \n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tidy_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>,- Tu es si adorable! Où as-tu eu cette chemise?</td>\n",
       "      <td>,- Tu es si adorable! Où as-tu eu cette chemise?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>,Oui, il est vraiment très lol</td>\n",
       "      <td>,Oui, il est vraiment très lol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>,- Thé vert, une boisson pour me faire plaisir.</td>\n",
       "      <td>,- Thé vert, une boisson pour me faire plaisir.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>,Je parlais de ne pas savoir comment épeler un mot et mal orthographié un tas! Oops! Parlez-en!</td>\n",
       "      <td>,Je parlais de ne pas savoir comment épeler un mot et mal orthographié un tas! Oops! Parlez-en!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>,Hey quoi de neuf et d'accueil</td>\n",
       "      <td>,Hey quoi de neuf et d'accueil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment  \\\n",
       "0  POSITIVE   \n",
       "1  POSITIVE   \n",
       "2  POSITIVE   \n",
       "3  POSITIVE   \n",
       "4  POSITIVE   \n",
       "\n",
       "                                                                                        tweet_text  \\\n",
       "0                                                 ,- Tu es si adorable! Où as-tu eu cette chemise?   \n",
       "1                                                                   ,Oui, il est vraiment très lol   \n",
       "2                                                  ,- Thé vert, une boisson pour me faire plaisir.   \n",
       "3  ,Je parlais de ne pas savoir comment épeler un mot et mal orthographié un tas! Oops! Parlez-en!   \n",
       "4                                                                   ,Hey quoi de neuf et d'accueil   \n",
       "\n",
       "                                                                                        tidy_tweet  \n",
       "0                                                 ,- Tu es si adorable! Où as-tu eu cette chemise?  \n",
       "1                                                                   ,Oui, il est vraiment très lol  \n",
       "2                                                  ,- Thé vert, une boisson pour me faire plaisir.  \n",
       "3  ,Je parlais de ne pas savoir comment épeler un mot et mal orthographié un tas! Oops! Parlez-en!  \n",
       "4                                                                   ,Hey quoi de neuf et d'accueil  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['tidy_tweet'] = np.vectorize(remove_pattern)(train['tidy_tweet'], \"#[\\w]*\") \n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Web Addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tidy_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>,- Tu es si adorable! Où as-tu eu cette chemise?</td>\n",
       "      <td>,- Tu es si adorable! Où as-tu eu cette chemise?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>,Oui, il est vraiment très lol</td>\n",
       "      <td>,Oui, il est vraiment très lol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>,- Thé vert, une boisson pour me faire plaisir.</td>\n",
       "      <td>,- Thé vert, une boisson pour me faire plaisir.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>,Je parlais de ne pas savoir comment épeler un mot et mal orthographié un tas! Oops! Parlez-en!</td>\n",
       "      <td>,Je parlais de ne pas savoir comment épeler un mot et mal orthographié un tas! Oops! Parlez-en!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>,Hey quoi de neuf et d'accueil</td>\n",
       "      <td>,Hey quoi de neuf et d'accueil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment  \\\n",
       "0  POSITIVE   \n",
       "1  POSITIVE   \n",
       "2  POSITIVE   \n",
       "3  POSITIVE   \n",
       "4  POSITIVE   \n",
       "\n",
       "                                                                                        tweet_text  \\\n",
       "0                                                 ,- Tu es si adorable! Où as-tu eu cette chemise?   \n",
       "1                                                                   ,Oui, il est vraiment très lol   \n",
       "2                                                  ,- Thé vert, une boisson pour me faire plaisir.   \n",
       "3  ,Je parlais de ne pas savoir comment épeler un mot et mal orthographié un tas! Oops! Parlez-en!   \n",
       "4                                                                   ,Hey quoi de neuf et d'accueil   \n",
       "\n",
       "                                                                                        tidy_tweet  \n",
       "0                                                 ,- Tu es si adorable! Où as-tu eu cette chemise?  \n",
       "1                                                                   ,Oui, il est vraiment très lol  \n",
       "2                                                  ,- Thé vert, une boisson pour me faire plaisir.  \n",
       "3  ,Je parlais de ne pas savoir comment épeler un mot et mal orthographié un tas! Oops! Parlez-en!  \n",
       "4                                                                   ,Hey quoi de neuf et d'accueil  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['tidy_tweet'] = train['tidy_tweet'].str.replace(\"(\\w+:\\/\\/\\S+)\", \" \")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Punctuations & Special Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tidy_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>,- Tu es si adorable! Où as-tu eu cette chemise?</td>\n",
       "      <td>Tu es si adorable  Où as tu eu cette chemise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>,Oui, il est vraiment très lol</td>\n",
       "      <td>Oui  il est vraiment très lol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>,- Thé vert, une boisson pour me faire plaisir.</td>\n",
       "      <td>Thé vert  une boisson pour me faire plaisir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>,Je parlais de ne pas savoir comment épeler un mot et mal orthographié un tas! Oops! Parlez-en!</td>\n",
       "      <td>Je parlais de ne pas savoir comment épeler un mot et mal orthographié un tas  Oops  Parlez en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>,Hey quoi de neuf et d'accueil</td>\n",
       "      <td>Hey quoi de neuf et d'accueil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment  \\\n",
       "0  POSITIVE   \n",
       "1  POSITIVE   \n",
       "2  POSITIVE   \n",
       "3  POSITIVE   \n",
       "4  POSITIVE   \n",
       "\n",
       "                                                                                        tweet_text  \\\n",
       "0                                                 ,- Tu es si adorable! Où as-tu eu cette chemise?   \n",
       "1                                                                   ,Oui, il est vraiment très lol   \n",
       "2                                                  ,- Thé vert, une boisson pour me faire plaisir.   \n",
       "3  ,Je parlais de ne pas savoir comment épeler un mot et mal orthographié un tas! Oops! Parlez-en!   \n",
       "4                                                                   ,Hey quoi de neuf et d'accueil   \n",
       "\n",
       "                                                                                        tidy_tweet  \n",
       "0                                                    Tu es si adorable  Où as tu eu cette chemise   \n",
       "1                                                                    Oui  il est vraiment très lol  \n",
       "2                                                     Thé vert  une boisson pour me faire plaisir   \n",
       "3   Je parlais de ne pas savoir comment épeler un mot et mal orthographié un tas  Oops  Parlez en   \n",
       "4                                                                    Hey quoi de neuf et d'accueil  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['tidy_tweet'] = train['tidy_tweet'].str.replace(\"[\\.\\,\\!\\?\\:\\;\\-\\=*$%^&(){}~<>€|\\\"]\", \" \")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tidy_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>,C'était une excellente idée, je l'ai invitée au marché de Queen Vic avec moi le vendredi. Cela s'est avéré que c'était bon vendredi et qu'il était fermé.</td>\n",
       "      <td>C'était une excellente idée  je l'ai invitée au marché de Queen Vic avec moi le vendredi  Cela s'est avéré que c'était bon vendredi et qu'il était fermé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>,En espérant que mon chien s'améliore mieux !!! Elle devait aller au chien de bière hier soir</td>\n",
       "      <td>En espérant que mon chien s'améliore mieux     Elle devait aller au chien de bière hier soir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>,Étude d'étude. Il semble être sans fin. Des tests tout le temps.</td>\n",
       "      <td>Étude d'étude  Il semble être sans fin  Des tests tout le temps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>,Oui, je sais qu'ils se rendent bientôt aux États-Unis, mais je ne pouvais pas y aller, c'est pendant la semaine en philly</td>\n",
       "      <td>Oui  je sais qu'ils se rendent bientôt aux États Unis  mais je ne pouvais pas y aller  c'est pendant la semaine en philly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>,vomir. Urgh</td>\n",
       "      <td>vomir  Urgh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sentiment  \\\n",
       "9995  NEGATIVE   \n",
       "9996  NEGATIVE   \n",
       "9997  NEGATIVE   \n",
       "9998  NEGATIVE   \n",
       "9999  NEGATIVE   \n",
       "\n",
       "                                                                                                                                                      tweet_text  \\\n",
       "9995  ,C'était une excellente idée, je l'ai invitée au marché de Queen Vic avec moi le vendredi. Cela s'est avéré que c'était bon vendredi et qu'il était fermé.   \n",
       "9996                                                               ,En espérant que mon chien s'améliore mieux !!! Elle devait aller au chien de bière hier soir   \n",
       "9997                                                                                           ,Étude d'étude. Il semble être sans fin. Des tests tout le temps.   \n",
       "9998                                  ,Oui, je sais qu'ils se rendent bientôt aux États-Unis, mais je ne pouvais pas y aller, c'est pendant la semaine en philly   \n",
       "9999                                                                                                                                                ,vomir. Urgh   \n",
       "\n",
       "                                                                                                                                                      tidy_tweet  \n",
       "9995   C'était une excellente idée  je l'ai invitée au marché de Queen Vic avec moi le vendredi  Cela s'est avéré que c'était bon vendredi et qu'il était fermé   \n",
       "9996                                                                En espérant que mon chien s'améliore mieux     Elle devait aller au chien de bière hier soir  \n",
       "9997                                                                                            Étude d'étude  Il semble être sans fin  Des tests tout le temps   \n",
       "9998                                   Oui  je sais qu'ils se rendent bientôt aux États Unis  mais je ne pouvais pas y aller  c'est pendant la semaine en philly  \n",
       "9999                                                                                                                                                 vomir  Urgh  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['tidy_tweet'] = train['tidy_tweet'].str.replace('\"', '')\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tidy_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>,C'était une excellente idée, je l'ai invitée au marché de Queen Vic avec moi le vendredi. Cela s'est avéré que c'était bon vendredi et qu'il était fermé.</td>\n",
       "      <td>C'était une excellente idée  je l'ai invitée au marché de Queen Vic avec moi le vendredi  Cela s'est avéré que c'était bon vendredi et qu'il était fermé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>,En espérant que mon chien s'améliore mieux !!! Elle devait aller au chien de bière hier soir</td>\n",
       "      <td>En espérant que mon chien s'améliore mieux     Elle devait aller au chien de bière hier soir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>,Étude d'étude. Il semble être sans fin. Des tests tout le temps.</td>\n",
       "      <td>Étude d'étude  Il semble être sans fin  Des tests tout le temps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>,Oui, je sais qu'ils se rendent bientôt aux États-Unis, mais je ne pouvais pas y aller, c'est pendant la semaine en philly</td>\n",
       "      <td>Oui  je sais qu'ils se rendent bientôt aux États Unis  mais je ne pouvais pas y aller  c'est pendant la semaine en philly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>,vomir. Urgh</td>\n",
       "      <td>vomir  Urgh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sentiment  \\\n",
       "9995  NEGATIVE   \n",
       "9996  NEGATIVE   \n",
       "9997  NEGATIVE   \n",
       "9998  NEGATIVE   \n",
       "9999  NEGATIVE   \n",
       "\n",
       "                                                                                                                                                      tweet_text  \\\n",
       "9995  ,C'était une excellente idée, je l'ai invitée au marché de Queen Vic avec moi le vendredi. Cela s'est avéré que c'était bon vendredi et qu'il était fermé.   \n",
       "9996                                                               ,En espérant que mon chien s'améliore mieux !!! Elle devait aller au chien de bière hier soir   \n",
       "9997                                                                                           ,Étude d'étude. Il semble être sans fin. Des tests tout le temps.   \n",
       "9998                                  ,Oui, je sais qu'ils se rendent bientôt aux États-Unis, mais je ne pouvais pas y aller, c'est pendant la semaine en philly   \n",
       "9999                                                                                                                                                ,vomir. Urgh   \n",
       "\n",
       "                                                                                                                                                      tidy_tweet  \n",
       "9995   C'était une excellente idée  je l'ai invitée au marché de Queen Vic avec moi le vendredi  Cela s'est avéré que c'était bon vendredi et qu'il était fermé   \n",
       "9996                                                                En espérant que mon chien s'améliore mieux     Elle devait aller au chien de bière hier soir  \n",
       "9997                                                                                            Étude d'étude  Il semble être sans fin  Des tests tout le temps   \n",
       "9998                                   Oui  je sais qu'ils se rendent bientôt aux États Unis  mais je ne pouvais pas y aller  c'est pendant la semaine en philly  \n",
       "9999                                                                                                                                                 vomir  Urgh  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['tidy_tweet'] = train['tidy_tweet'].str.replace(\"^\\d+\\s|\\s\\d+\\s|\\s\\d+$\", \" \")\n",
    "train.tail()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting to Lower Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tidy_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>,- Tu es si adorable! Où as-tu eu cette chemise?</td>\n",
       "      <td>tu es si adorable  où as tu eu cette chemise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>,Oui, il est vraiment très lol</td>\n",
       "      <td>oui  il est vraiment très lol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>,- Thé vert, une boisson pour me faire plaisir.</td>\n",
       "      <td>thé vert  une boisson pour me faire plaisir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>,Je parlais de ne pas savoir comment épeler un mot et mal orthographié un tas! Oops! Parlez-en!</td>\n",
       "      <td>je parlais de ne pas savoir comment épeler un mot et mal orthographié un tas  oops  parlez en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>,Hey quoi de neuf et d'accueil</td>\n",
       "      <td>hey quoi de neuf et d'accueil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment  \\\n",
       "0  POSITIVE   \n",
       "1  POSITIVE   \n",
       "2  POSITIVE   \n",
       "3  POSITIVE   \n",
       "4  POSITIVE   \n",
       "\n",
       "                                                                                        tweet_text  \\\n",
       "0                                                 ,- Tu es si adorable! Où as-tu eu cette chemise?   \n",
       "1                                                                   ,Oui, il est vraiment très lol   \n",
       "2                                                  ,- Thé vert, une boisson pour me faire plaisir.   \n",
       "3  ,Je parlais de ne pas savoir comment épeler un mot et mal orthographié un tas! Oops! Parlez-en!   \n",
       "4                                                                   ,Hey quoi de neuf et d'accueil   \n",
       "\n",
       "                                                                                        tidy_tweet  \n",
       "0                                                    tu es si adorable  où as tu eu cette chemise   \n",
       "1                                                                    oui  il est vraiment très lol  \n",
       "2                                                     thé vert  une boisson pour me faire plaisir   \n",
       "3   je parlais de ne pas savoir comment épeler un mot et mal orthographié un tas  oops  parlez en   \n",
       "4                                                                    hey quoi de neuf et d'accueil  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['tidy_tweet']=train['tidy_tweet'].str.lower()\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tidy_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>,- Tu es si adorable! Où as-tu eu cette chemise?</td>\n",
       "      <td>tu es si adorable   où as tu avoir ce chemise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>,Oui, il est vraiment très lol</td>\n",
       "      <td>oui   il être vraiment très lol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>,- Thé vert, une boisson pour me faire plaisir.</td>\n",
       "      <td>thé vert   un boisson pour me faire plaisir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>,Je parlais de ne pas savoir comment épeler un mot et mal orthographié un tas! Oops! Parlez-en!</td>\n",
       "      <td>je parler de ne pas savoir comment épeler un mot et mal orthographier un tas   oops   parler en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>,Hey quoi de neuf et d'accueil</td>\n",
       "      <td>hey quoi de neuf et de accueil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment  \\\n",
       "0  POSITIVE   \n",
       "1  POSITIVE   \n",
       "2  POSITIVE   \n",
       "3  POSITIVE   \n",
       "4  POSITIVE   \n",
       "\n",
       "                                                                                        tweet_text  \\\n",
       "0                                                 ,- Tu es si adorable! Où as-tu eu cette chemise?   \n",
       "1                                                                   ,Oui, il est vraiment très lol   \n",
       "2                                                  ,- Thé vert, une boisson pour me faire plaisir.   \n",
       "3  ,Je parlais de ne pas savoir comment épeler un mot et mal orthographié un tas! Oops! Parlez-en!   \n",
       "4                                                                   ,Hey quoi de neuf et d'accueil   \n",
       "\n",
       "                                                                                          tidy_tweet  \n",
       "0                                                      tu es si adorable   où as tu avoir ce chemise  \n",
       "1                                                                    oui   il être vraiment très lol  \n",
       "2                                                        thé vert   un boisson pour me faire plaisir  \n",
       "3    je parler de ne pas savoir comment épeler un mot et mal orthographier un tas   oops   parler en  \n",
       "4                                                                     hey quoi de neuf et de accueil  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['tidy_tweet']=train['tidy_tweet'].apply(lambda row: \" \".join([w.lemma_ for w in nlp(row)]))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = train['tidy_tweet'].str.split().str.len()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9925, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=train[~(count==1)]\n",
    "\n",
    "\n",
    "train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tidy_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>,- Tu es si adorable! Où as-tu eu cette chemise?</td>\n",
       "      <td>tu es si adorable   où as tu avoir ce chemise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>,Oui, il est vraiment très lol</td>\n",
       "      <td>oui   il être vraiment très lol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>,- Thé vert, une boisson pour me faire plaisir.</td>\n",
       "      <td>thé vert   un boisson pour me faire plaisir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>,Je parlais de ne pas savoir comment épeler un mot et mal orthographié un tas! Oops! Parlez-en!</td>\n",
       "      <td>je parler de ne pas savoir comment épeler un mot et mal orthographier un tas   oops   parler en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>,Hey quoi de neuf et d'accueil</td>\n",
       "      <td>hey quoi de neuf et de accueil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment  \\\n",
       "0  POSITIVE   \n",
       "1  POSITIVE   \n",
       "2  POSITIVE   \n",
       "3  POSITIVE   \n",
       "4  POSITIVE   \n",
       "\n",
       "                                                                                        tweet_text  \\\n",
       "0                                                 ,- Tu es si adorable! Où as-tu eu cette chemise?   \n",
       "1                                                                   ,Oui, il est vraiment très lol   \n",
       "2                                                  ,- Thé vert, une boisson pour me faire plaisir.   \n",
       "3  ,Je parlais de ne pas savoir comment épeler un mot et mal orthographié un tas! Oops! Parlez-en!   \n",
       "4                                                                   ,Hey quoi de neuf et d'accueil   \n",
       "\n",
       "                                                                                          tidy_tweet  \n",
       "0                                                      tu es si adorable   où as tu avoir ce chemise  \n",
       "1                                                                    oui   il être vraiment très lol  \n",
       "2                                                        thé vert   un boisson pour me faire plaisir  \n",
       "3    je parler de ne pas savoir comment épeler un mot et mal orthographier un tas   oops   parler en  \n",
       "4                                                                     hey quoi de neuf et de accueil  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NEGATIVE    4984\n",
       "POSITIVE    4941\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9925, 3000)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.90, min_df=2, max_features=3000,ngram_range=(1,1))\n",
    "tfidf = tfidf_vectorizer.fit_transform(train['tidy_tweet'])\n",
    "tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2990</th>\n",
       "      <th>2991</th>\n",
       "      <th>2992</th>\n",
       "      <th>2993</th>\n",
       "      <th>2994</th>\n",
       "      <th>2995</th>\n",
       "      <th>2996</th>\n",
       "      <th>2997</th>\n",
       "      <th>2998</th>\n",
       "      <th>2999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.186291</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2     3     4     5     6     7     8     9     ...  2990  \\\n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "\n",
       "   2991  2992  2993  2994  2995      2996  2997  2998  2999  \n",
       "0   0.0   0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0   0.0   0.0  0.186291   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0  \n",
       "3   0.0   0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0  \n",
       "4   0.0   0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 3000 columns]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A=tfidf\n",
    "y=train['sentiment']\n",
    "A = pd.DataFrame(A.toarray())\n",
    "A.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9925, 3000)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.90, min_df=2, max_features=3000,ngram_range=(2,2))\n",
    "tfidf = tfidf_vectorizer.fit_transform(train['tidy_tweet'])\n",
    "tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2990</th>\n",
       "      <th>2991</th>\n",
       "      <th>2992</th>\n",
       "      <th>2993</th>\n",
       "      <th>2994</th>\n",
       "      <th>2995</th>\n",
       "      <th>2996</th>\n",
       "      <th>2997</th>\n",
       "      <th>2998</th>\n",
       "      <th>2999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.439918</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2     3     4     5     6     7     8     9     ...  2990  \\\n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "\n",
       "   2991  2992  2993  2994      2995  2996  2997  2998  2999  \n",
       "0   0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0   0.0  0.439918   0.0   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0   0.0  \n",
       "3   0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0   0.0  \n",
       "4   0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 3000 columns]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B=tfidf\n",
    "y=train['sentiment']\n",
    "B = pd.DataFrame(B.toarray())\n",
    "B.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unigrams+Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9925, 3000)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.90, min_df=2, max_features=3000,ngram_range=(1,2))\n",
    "tfidf = tfidf_vectorizer.fit_transform(train['tidy_tweet'])\n",
    "tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9925, 3000)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C=tfidf\n",
    "y=train['sentiment']\n",
    "C = pd.DataFrame(C.toarray())\n",
    "C.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9925, 3000)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.90, min_df=2, max_features=3000,ngram_range=(3,3))\n",
    "tfidf = tfidf_vectorizer.fit_transform(train['tidy_tweet'])\n",
    "tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9925, 3000)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D=tfidf\n",
    "y=train['sentiment']\n",
    "D = pd.DataFrame(D.toarray())\n",
    "D.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uni+Bi+Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9925, 3000)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.90, min_df=2, max_features=3000,ngram_range=(1,3))\n",
    "tfidf = tfidf_vectorizer.fit_transform(train['tidy_tweet'])\n",
    "tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9925, 3000)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E=tfidf\n",
    "y=train['sentiment']\n",
    "E = pd.DataFrame(E.toarray())\n",
    "E.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 of kfold 5\n",
      "accuracy_score 0.74911838790932\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.75      0.74      0.75       996\n",
      "    NEGATIVE       0.74      0.76      0.75       989\n",
      "\n",
      "    accuracy                           0.75      1985\n",
      "   macro avg       0.75      0.75      0.75      1985\n",
      "weighted avg       0.75      0.75      0.75      1985\n",
      "\n",
      "\n",
      "2 of kfold 5\n",
      "accuracy_score 0.7314861460957179\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.74      0.72      0.73       997\n",
      "    NEGATIVE       0.72      0.74      0.73       988\n",
      "\n",
      "    accuracy                           0.73      1985\n",
      "   macro avg       0.73      0.73      0.73      1985\n",
      "weighted avg       0.73      0.73      0.73      1985\n",
      "\n",
      "\n",
      "3 of kfold 5\n",
      "accuracy_score 0.7370277078085642\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.74      0.74      0.74       997\n",
      "    NEGATIVE       0.74      0.74      0.74       988\n",
      "\n",
      "    accuracy                           0.74      1985\n",
      "   macro avg       0.74      0.74      0.74      1985\n",
      "weighted avg       0.74      0.74      0.74      1985\n",
      "\n",
      "\n",
      "4 of kfold 5\n",
      "accuracy_score 0.7148614609571788\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.72      0.70      0.71       997\n",
      "    NEGATIVE       0.71      0.73      0.72       988\n",
      "\n",
      "    accuracy                           0.71      1985\n",
      "   macro avg       0.72      0.71      0.71      1985\n",
      "weighted avg       0.72      0.71      0.71      1985\n",
      "\n",
      "\n",
      "5 of kfold 5\n",
      "accuracy_score 0.7324937027707809\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.74      0.72      0.73       997\n",
      "    NEGATIVE       0.73      0.74      0.73       988\n",
      "\n",
      "    accuracy                           0.73      1985\n",
      "   macro avg       0.73      0.73      0.73      1985\n",
      "weighted avg       0.73      0.73      0.73      1985\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "i=1\n",
    "kf = StratifiedKFold(n_splits=5,random_state=1,shuffle=True)\n",
    "for train_index,test_index in kf.split(A,y):\n",
    "     print('\\n{} of kfold {}'.format(i,kf.n_splits))\n",
    "     xtr,xvl = A.loc[train_index],A.loc[test_index]\n",
    "     ytr,yvl = y[train_index],y[test_index]\n",
    "    \n",
    "     model =  LogisticRegression()\n",
    "     model.fit(xtr, ytr)\n",
    "     pred_test = model.predict(xvl)\n",
    "     score = accuracy_score(yvl,pred_test)\n",
    "     print('accuracy_score',score)\n",
    "     target_names = ['POSITIVE','NEGATIVE']\n",
    "     print(classification_report(yvl, pred_test, target_names=target_names))\n",
    "     i+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 of kfold 5\n",
      "accuracy_score 0.7370277078085642\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.75      0.72      0.73       996\n",
      "    NEGATIVE       0.73      0.76      0.74       989\n",
      "\n",
      "    accuracy                           0.74      1985\n",
      "   macro avg       0.74      0.74      0.74      1985\n",
      "weighted avg       0.74      0.74      0.74      1985\n",
      "\n",
      "\n",
      "2 of kfold 5\n",
      "accuracy_score 0.7178841309823678\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.73      0.69      0.71       997\n",
      "    NEGATIVE       0.71      0.74      0.72       988\n",
      "\n",
      "    accuracy                           0.72      1985\n",
      "   macro avg       0.72      0.72      0.72      1985\n",
      "weighted avg       0.72      0.72      0.72      1985\n",
      "\n",
      "\n",
      "3 of kfold 5\n",
      "accuracy_score 0.7445843828715365\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.76      0.72      0.74       997\n",
      "    NEGATIVE       0.73      0.77      0.75       988\n",
      "\n",
      "    accuracy                           0.74      1985\n",
      "   macro avg       0.75      0.74      0.74      1985\n",
      "weighted avg       0.75      0.74      0.74      1985\n",
      "\n",
      "\n",
      "4 of kfold 5\n",
      "accuracy_score 0.7073047858942065\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.72      0.69      0.70       997\n",
      "    NEGATIVE       0.70      0.73      0.71       988\n",
      "\n",
      "    accuracy                           0.71      1985\n",
      "   macro avg       0.71      0.71      0.71      1985\n",
      "weighted avg       0.71      0.71      0.71      1985\n",
      "\n",
      "\n",
      "5 of kfold 5\n",
      "accuracy_score 0.7299748110831235\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.75      0.70      0.72       997\n",
      "    NEGATIVE       0.72      0.76      0.74       988\n",
      "\n",
      "    accuracy                           0.73      1985\n",
      "   macro avg       0.73      0.73      0.73      1985\n",
      "weighted avg       0.73      0.73      0.73      1985\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "i=1\n",
    "kf = StratifiedKFold(n_splits=5,random_state=1,shuffle=True)\n",
    "for train_index,test_index in kf.split(A,y):\n",
    "     print('\\n{} of kfold {}'.format(i,kf.n_splits))\n",
    "     xtr,xvl = A.loc[train_index],A.loc[test_index]\n",
    "     ytr,yvl = y[train_index],y[test_index]\n",
    "     #sm=SMOTE(random_state=1)\n",
    "     #xtr,ytr=sm.fit_sample(xtr,ytr)\n",
    "     model = BernoulliNB()\n",
    "     model.fit(xtr, ytr)\n",
    "     pred_test = model.predict(xvl)\n",
    "     score = accuracy_score(yvl,pred_test)\n",
    "     print('accuracy_score',score)\n",
    "     target_names = ['POSITIVE','NEGATIVE']\n",
    "     print(classification_report(yvl, pred_test, target_names=target_names))\n",
    "     i+=1 \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 of kfold 5\n",
      "accuracy_score 0.74911838790932\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.78      0.70      0.74       996\n",
      "    NEGATIVE       0.73      0.80      0.76       989\n",
      "\n",
      "    accuracy                           0.75      1985\n",
      "   macro avg       0.75      0.75      0.75      1985\n",
      "weighted avg       0.75      0.75      0.75      1985\n",
      "\n",
      "\n",
      "2 of kfold 5\n",
      "accuracy_score 0.7329974811083123\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.72      0.76      0.74       997\n",
      "    NEGATIVE       0.74      0.71      0.73       988\n",
      "\n",
      "    accuracy                           0.73      1985\n",
      "   macro avg       0.73      0.73      0.73      1985\n",
      "weighted avg       0.73      0.73      0.73      1985\n",
      "\n",
      "\n",
      "3 of kfold 5\n",
      "accuracy_score 0.7224181360201511\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.68      0.85      0.76       997\n",
      "    NEGATIVE       0.80      0.59      0.68       988\n",
      "\n",
      "    accuracy                           0.72      1985\n",
      "   macro avg       0.74      0.72      0.72      1985\n",
      "weighted avg       0.74      0.72      0.72      1985\n",
      "\n",
      "\n",
      "4 of kfold 5\n",
      "accuracy_score 0.7163727959697733\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.73      0.70      0.71       997\n",
      "    NEGATIVE       0.71      0.73      0.72       988\n",
      "\n",
      "    accuracy                           0.72      1985\n",
      "   macro avg       0.72      0.72      0.72      1985\n",
      "weighted avg       0.72      0.72      0.72      1985\n",
      "\n",
      "\n",
      "5 of kfold 5\n",
      "accuracy_score 0.7289672544080604\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.76      0.68      0.72       997\n",
      "    NEGATIVE       0.71      0.78      0.74       988\n",
      "\n",
      "    accuracy                           0.73      1985\n",
      "   macro avg       0.73      0.73      0.73      1985\n",
      "weighted avg       0.73      0.73      0.73      1985\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "i=1\n",
    "kf = StratifiedKFold(n_splits=5,random_state=1,shuffle=True)\n",
    "for train_index,test_index in kf.split(A,y):\n",
    "     print('\\n{} of kfold {}'.format(i,kf.n_splits))\n",
    "     xtr,xvl = A.loc[train_index],A.loc[test_index]\n",
    "     ytr,yvl = y[train_index],y[test_index]\n",
    "     #sm=SMOTE(random_state=1)\n",
    "     #xtr,ytr=sm.fit_sample(xtr,ytr)\n",
    "     model = SGDClassifier(loss='log',penalty='elasticnet')\n",
    "     model.fit(xtr, ytr)\n",
    "     pred_test = model.predict(xvl)\n",
    "     score = accuracy_score(yvl,pred_test)\n",
    "     print('accuracy_score',score)\n",
    "     target_names = ['POSITIVE','NEGATIVE']\n",
    "     print(classification_report(yvl, pred_test, target_names=target_names))\n",
    "     i+=1\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 of kfold 5\n",
      "accuracy_score 0.6962216624685138\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.71      0.67      0.69       996\n",
      "    NEGATIVE       0.69      0.72      0.70       989\n",
      "\n",
      "    accuracy                           0.70      1985\n",
      "   macro avg       0.70      0.70      0.70      1985\n",
      "weighted avg       0.70      0.70      0.70      1985\n",
      "\n",
      "\n",
      "2 of kfold 5\n",
      "accuracy_score 0.6886649874055416\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.71      0.65      0.68       997\n",
      "    NEGATIVE       0.67      0.72      0.70       988\n",
      "\n",
      "    accuracy                           0.69      1985\n",
      "   macro avg       0.69      0.69      0.69      1985\n",
      "weighted avg       0.69      0.69      0.69      1985\n",
      "\n",
      "\n",
      "3 of kfold 5\n",
      "accuracy_score 0.6806045340050377\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.70      0.64      0.67       997\n",
      "    NEGATIVE       0.66      0.72      0.69       988\n",
      "\n",
      "    accuracy                           0.68      1985\n",
      "   macro avg       0.68      0.68      0.68      1985\n",
      "weighted avg       0.68      0.68      0.68      1985\n",
      "\n",
      "\n",
      "4 of kfold 5\n",
      "accuracy_score 0.6790931989924434\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.69      0.66      0.67       997\n",
      "    NEGATIVE       0.67      0.70      0.69       988\n",
      "\n",
      "    accuracy                           0.68      1985\n",
      "   macro avg       0.68      0.68      0.68      1985\n",
      "weighted avg       0.68      0.68      0.68      1985\n",
      "\n",
      "\n",
      "5 of kfold 5\n",
      "accuracy_score 0.6846347607052897\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.70      0.65      0.67       997\n",
      "    NEGATIVE       0.67      0.72      0.70       988\n",
      "\n",
      "    accuracy                           0.68      1985\n",
      "   macro avg       0.69      0.68      0.68      1985\n",
      "weighted avg       0.69      0.68      0.68      1985\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "i=1\n",
    "kf = StratifiedKFold(n_splits=5,random_state=1,shuffle=True)\n",
    "for train_index,test_index in kf.split(B,y):\n",
    "     print('\\n{} of kfold {}'.format(i,kf.n_splits))\n",
    "     xtr,xvl = B.loc[train_index],B.loc[test_index]\n",
    "     ytr,yvl = y[train_index],y[test_index]\n",
    "    \n",
    "     model =  LogisticRegression()\n",
    "     model.fit(xtr, ytr)\n",
    "     pred_test = model.predict(xvl)\n",
    "     score = accuracy_score(yvl,pred_test)\n",
    "     print('accuracy_score',score)\n",
    "     target_names = ['POSITIVE','NEGATIVE']\n",
    "     print(classification_report(yvl, pred_test, target_names=target_names))\n",
    "     i+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 of kfold 5\n",
      "accuracy_score 0.6982367758186397\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.74      0.62      0.67       996\n",
      "    NEGATIVE       0.67      0.77      0.72       989\n",
      "\n",
      "    accuracy                           0.70      1985\n",
      "   macro avg       0.70      0.70      0.70      1985\n",
      "weighted avg       0.70      0.70      0.70      1985\n",
      "\n",
      "\n",
      "2 of kfold 5\n",
      "accuracy_score 0.6801007556675063\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.72      0.60      0.65       997\n",
      "    NEGATIVE       0.65      0.76      0.70       988\n",
      "\n",
      "    accuracy                           0.68      1985\n",
      "   macro avg       0.69      0.68      0.68      1985\n",
      "weighted avg       0.69      0.68      0.68      1985\n",
      "\n",
      "\n",
      "3 of kfold 5\n",
      "accuracy_score 0.6780856423173803\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.71      0.60      0.65       997\n",
      "    NEGATIVE       0.65      0.76      0.70       988\n",
      "\n",
      "    accuracy                           0.68      1985\n",
      "   macro avg       0.68      0.68      0.68      1985\n",
      "weighted avg       0.68      0.68      0.68      1985\n",
      "\n",
      "\n",
      "4 of kfold 5\n",
      "accuracy_score 0.6664987405541561\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.69      0.60      0.64       997\n",
      "    NEGATIVE       0.64      0.73      0.69       988\n",
      "\n",
      "    accuracy                           0.67      1985\n",
      "   macro avg       0.67      0.67      0.67      1985\n",
      "weighted avg       0.67      0.67      0.66      1985\n",
      "\n",
      "\n",
      "5 of kfold 5\n",
      "accuracy_score 0.6856423173803526\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.73      0.60      0.66       997\n",
      "    NEGATIVE       0.66      0.78      0.71       988\n",
      "\n",
      "    accuracy                           0.69      1985\n",
      "   macro avg       0.69      0.69      0.68      1985\n",
      "weighted avg       0.69      0.69      0.68      1985\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "i=1\n",
    "kf = StratifiedKFold(n_splits=5,random_state=1,shuffle=True)\n",
    "for train_index,test_index in kf.split(B,y):\n",
    "     print('\\n{} of kfold {}'.format(i,kf.n_splits))\n",
    "     xtr,xvl = B.loc[train_index],B.loc[test_index]\n",
    "     ytr,yvl = y[train_index],y[test_index]\n",
    "     #sm=SMOTE(random_state=1)\n",
    "     #xtr,ytr=sm.fit_sample(xtr,ytr)\n",
    "     model = BernoulliNB()\n",
    "     model.fit(xtr, ytr)\n",
    "     pred_test = model.predict(xvl)\n",
    "     score = accuracy_score(yvl,pred_test)\n",
    "     print('accuracy_score',score)\n",
    "     target_names = ['POSITIVE','NEGATIVE']\n",
    "     print(classification_report(yvl, pred_test, target_names=target_names))\n",
    "     i+=1 \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 of kfold 5\n",
      "accuracy_score 0.690176322418136\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.76      0.56      0.64       996\n",
      "    NEGATIVE       0.65      0.83      0.73       989\n",
      "\n",
      "    accuracy                           0.69      1985\n",
      "   macro avg       0.71      0.69      0.68      1985\n",
      "weighted avg       0.71      0.69      0.68      1985\n",
      "\n",
      "\n",
      "2 of kfold 5\n",
      "accuracy_score 0.68816120906801\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.73      0.61      0.66       997\n",
      "    NEGATIVE       0.66      0.77      0.71       988\n",
      "\n",
      "    accuracy                           0.69      1985\n",
      "   macro avg       0.69      0.69      0.69      1985\n",
      "weighted avg       0.69      0.69      0.69      1985\n",
      "\n",
      "\n",
      "3 of kfold 5\n",
      "accuracy_score 0.672544080604534\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.70      0.61      0.65       997\n",
      "    NEGATIVE       0.65      0.73      0.69       988\n",
      "\n",
      "    accuracy                           0.67      1985\n",
      "   macro avg       0.68      0.67      0.67      1985\n",
      "weighted avg       0.68      0.67      0.67      1985\n",
      "\n",
      "\n",
      "4 of kfold 5\n",
      "accuracy_score 0.6700251889168766\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.70      0.60      0.65       997\n",
      "    NEGATIVE       0.65      0.74      0.69       988\n",
      "\n",
      "    accuracy                           0.67      1985\n",
      "   macro avg       0.67      0.67      0.67      1985\n",
      "weighted avg       0.67      0.67      0.67      1985\n",
      "\n",
      "\n",
      "5 of kfold 5\n",
      "accuracy_score 0.6785894206549118\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.71      0.61      0.66       997\n",
      "    NEGATIVE       0.65      0.75      0.70       988\n",
      "\n",
      "    accuracy                           0.68      1985\n",
      "   macro avg       0.68      0.68      0.68      1985\n",
      "weighted avg       0.68      0.68      0.68      1985\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "i=1\n",
    "kf = StratifiedKFold(n_splits=5,random_state=1,shuffle=True)\n",
    "for train_index,test_index in kf.split(B,y):\n",
    "     print('\\n{} of kfold {}'.format(i,kf.n_splits))\n",
    "     xtr,xvl = B.loc[train_index],B.loc[test_index]\n",
    "     ytr,yvl = y[train_index],y[test_index]\n",
    "     #sm=SMOTE(random_state=1)\n",
    "     #xtr,ytr=sm.fit_sample(xtr,ytr)\n",
    "     model = SGDClassifier(loss='log',penalty='elasticnet')\n",
    "     model.fit(xtr, ytr)\n",
    "     pred_test = model.predict(xvl)\n",
    "     score = accuracy_score(yvl,pred_test)\n",
    "     print('accuracy_score',score)\n",
    "     target_names = ['POSITIVE','NEGATIVE']\n",
    "     print(classification_report(yvl, pred_test, target_names=target_names))\n",
    "     i+=1\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unigrams + Bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 of kfold 5\n",
      "accuracy_score 0.747103274559194\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.75      0.74      0.75       996\n",
      "    NEGATIVE       0.74      0.76      0.75       989\n",
      "\n",
      "    accuracy                           0.75      1985\n",
      "   macro avg       0.75      0.75      0.75      1985\n",
      "weighted avg       0.75      0.75      0.75      1985\n",
      "\n",
      "\n",
      "2 of kfold 5\n",
      "accuracy_score 0.7324937027707809\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.73      0.73      0.73       997\n",
      "    NEGATIVE       0.73      0.73      0.73       988\n",
      "\n",
      "    accuracy                           0.73      1985\n",
      "   macro avg       0.73      0.73      0.73      1985\n",
      "weighted avg       0.73      0.73      0.73      1985\n",
      "\n",
      "\n",
      "3 of kfold 5\n",
      "accuracy_score 0.7375314861460958\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.74      0.74      0.74       997\n",
      "    NEGATIVE       0.74      0.74      0.74       988\n",
      "\n",
      "    accuracy                           0.74      1985\n",
      "   macro avg       0.74      0.74      0.74      1985\n",
      "weighted avg       0.74      0.74      0.74      1985\n",
      "\n",
      "\n",
      "4 of kfold 5\n",
      "accuracy_score 0.7123425692695214\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.72      0.69      0.71       997\n",
      "    NEGATIVE       0.70      0.73      0.72       988\n",
      "\n",
      "    accuracy                           0.71      1985\n",
      "   macro avg       0.71      0.71      0.71      1985\n",
      "weighted avg       0.71      0.71      0.71      1985\n",
      "\n",
      "\n",
      "5 of kfold 5\n",
      "accuracy_score 0.7329974811083123\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.74      0.73      0.73       997\n",
      "    NEGATIVE       0.73      0.74      0.73       988\n",
      "\n",
      "    accuracy                           0.73      1985\n",
      "   macro avg       0.73      0.73      0.73      1985\n",
      "weighted avg       0.73      0.73      0.73      1985\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "i=1\n",
    "kf = StratifiedKFold(n_splits=5,random_state=1,shuffle=True)\n",
    "for train_index,test_index in kf.split(C,y):\n",
    "     print('\\n{} of kfold {}'.format(i,kf.n_splits))\n",
    "     xtr,xvl = C.loc[train_index],C.loc[test_index]\n",
    "     ytr,yvl = y[train_index],y[test_index]\n",
    "    \n",
    "     model =  LogisticRegression()\n",
    "     model.fit(xtr, ytr)\n",
    "     pred_test = model.predict(xvl)\n",
    "     score = accuracy_score(yvl,pred_test)\n",
    "     print('accuracy_score',score)\n",
    "     target_names = ['POSITIVE','NEGATIVE']\n",
    "     print(classification_report(yvl, pred_test, target_names=target_names))\n",
    "     i+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 of kfold 5\n",
      "accuracy_score 0.7289672544080604\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.76      0.67      0.71       996\n",
      "    NEGATIVE       0.70      0.79      0.74       989\n",
      "\n",
      "    accuracy                           0.73      1985\n",
      "   macro avg       0.73      0.73      0.73      1985\n",
      "weighted avg       0.73      0.73      0.73      1985\n",
      "\n",
      "\n",
      "2 of kfold 5\n",
      "accuracy_score 0.7138539042821158\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.75      0.65      0.69       997\n",
      "    NEGATIVE       0.69      0.78      0.73       988\n",
      "\n",
      "    accuracy                           0.71      1985\n",
      "   macro avg       0.72      0.71      0.71      1985\n",
      "weighted avg       0.72      0.71      0.71      1985\n",
      "\n",
      "\n",
      "3 of kfold 5\n",
      "accuracy_score 0.7113350125944584\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.74      0.66      0.70       997\n",
      "    NEGATIVE       0.69      0.76      0.72       988\n",
      "\n",
      "    accuracy                           0.71      1985\n",
      "   macro avg       0.71      0.71      0.71      1985\n",
      "weighted avg       0.71      0.71      0.71      1985\n",
      "\n",
      "\n",
      "4 of kfold 5\n",
      "accuracy_score 0.6916876574307305\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.71      0.64      0.68       997\n",
      "    NEGATIVE       0.67      0.74      0.71       988\n",
      "\n",
      "    accuracy                           0.69      1985\n",
      "   macro avg       0.69      0.69      0.69      1985\n",
      "weighted avg       0.69      0.69      0.69      1985\n",
      "\n",
      "\n",
      "5 of kfold 5\n",
      "accuracy_score 0.7118387909319899\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.74      0.65      0.69       997\n",
      "    NEGATIVE       0.69      0.77      0.73       988\n",
      "\n",
      "    accuracy                           0.71      1985\n",
      "   macro avg       0.72      0.71      0.71      1985\n",
      "weighted avg       0.72      0.71      0.71      1985\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "i=1\n",
    "kf = StratifiedKFold(n_splits=5,random_state=1,shuffle=True)\n",
    "for train_index,test_index in kf.split(C,y):\n",
    "     print('\\n{} of kfold {}'.format(i,kf.n_splits))\n",
    "     xtr,xvl = C.loc[train_index],C.loc[test_index]\n",
    "     ytr,yvl = y[train_index],y[test_index]\n",
    "     #sm=SMOTE(random_state=1)\n",
    "     #xtr,ytr=sm.fit_sample(xtr,ytr)\n",
    "     model = BernoulliNB()\n",
    "     model.fit(xtr, ytr)\n",
    "     pred_test = model.predict(xvl)\n",
    "     score = accuracy_score(yvl,pred_test)\n",
    "     print('accuracy_score',score)\n",
    "     target_names = ['POSITIVE','NEGATIVE']\n",
    "     print(classification_report(yvl, pred_test, target_names=target_names))\n",
    "     i+=1 \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 of kfold 5\n",
      "accuracy_score 0.7465994962216624\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.75      0.73      0.74       996\n",
      "    NEGATIVE       0.74      0.76      0.75       989\n",
      "\n",
      "    accuracy                           0.75      1985\n",
      "   macro avg       0.75      0.75      0.75      1985\n",
      "weighted avg       0.75      0.75      0.75      1985\n",
      "\n",
      "\n",
      "2 of kfold 5\n",
      "accuracy_score 0.7299748110831235\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.73      0.74      0.73       997\n",
      "    NEGATIVE       0.73      0.72      0.73       988\n",
      "\n",
      "    accuracy                           0.73      1985\n",
      "   macro avg       0.73      0.73      0.73      1985\n",
      "weighted avg       0.73      0.73      0.73      1985\n",
      "\n",
      "\n",
      "3 of kfold 5\n",
      "accuracy_score 0.7385390428211587\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.76      0.71      0.73       997\n",
      "    NEGATIVE       0.72      0.77      0.75       988\n",
      "\n",
      "    accuracy                           0.74      1985\n",
      "   macro avg       0.74      0.74      0.74      1985\n",
      "weighted avg       0.74      0.74      0.74      1985\n",
      "\n",
      "\n",
      "4 of kfold 5\n",
      "accuracy_score 0.7163727959697733\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.74      0.66      0.70       997\n",
      "    NEGATIVE       0.69      0.77      0.73       988\n",
      "\n",
      "    accuracy                           0.72      1985\n",
      "   macro avg       0.72      0.72      0.72      1985\n",
      "weighted avg       0.72      0.72      0.72      1985\n",
      "\n",
      "\n",
      "5 of kfold 5\n",
      "accuracy_score 0.7279596977329975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.71      0.77      0.74       997\n",
      "    NEGATIVE       0.75      0.68      0.71       988\n",
      "\n",
      "    accuracy                           0.73      1985\n",
      "   macro avg       0.73      0.73      0.73      1985\n",
      "weighted avg       0.73      0.73      0.73      1985\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "i=1\n",
    "kf = StratifiedKFold(n_splits=5,random_state=1,shuffle=True)\n",
    "for train_index,test_index in kf.split(C,y):\n",
    "     print('\\n{} of kfold {}'.format(i,kf.n_splits))\n",
    "     xtr,xvl = C.loc[train_index],C.loc[test_index]\n",
    "     ytr,yvl = y[train_index],y[test_index]\n",
    "     #sm=SMOTE(random_state=1)\n",
    "     #xtr,ytr=sm.fit_sample(xtr,ytr)\n",
    "     model = SGDClassifier(loss='log',penalty='elasticnet')\n",
    "     model.fit(xtr, ytr)\n",
    "     pred_test = model.predict(xvl)\n",
    "     score = accuracy_score(yvl,pred_test)\n",
    "     print('accuracy_score',score)\n",
    "     target_names = ['POSITIVE','NEGATIVE']\n",
    "     print(classification_report(yvl, pred_test, target_names=target_names))\n",
    "     i+=1\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 of kfold 5\n",
      "accuracy_score 0.6458438287153653\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.70      0.52      0.60       996\n",
      "    NEGATIVE       0.61      0.77      0.69       989\n",
      "\n",
      "    accuracy                           0.65      1985\n",
      "   macro avg       0.66      0.65      0.64      1985\n",
      "weighted avg       0.66      0.65      0.64      1985\n",
      "\n",
      "\n",
      "2 of kfold 5\n",
      "accuracy_score 0.6408060453400504\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.69      0.53      0.60       997\n",
      "    NEGATIVE       0.61      0.76      0.68       988\n",
      "\n",
      "    accuracy                           0.64      1985\n",
      "   macro avg       0.65      0.64      0.64      1985\n",
      "weighted avg       0.65      0.64      0.64      1985\n",
      "\n",
      "\n",
      "3 of kfold 5\n",
      "accuracy_score 0.6267002518891688\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.66      0.52      0.58       997\n",
      "    NEGATIVE       0.60      0.73      0.66       988\n",
      "\n",
      "    accuracy                           0.63      1985\n",
      "   macro avg       0.63      0.63      0.62      1985\n",
      "weighted avg       0.63      0.63      0.62      1985\n",
      "\n",
      "\n",
      "4 of kfold 5\n",
      "accuracy_score 0.6367758186397985\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.68      0.53      0.60       997\n",
      "    NEGATIVE       0.61      0.74      0.67       988\n",
      "\n",
      "    accuracy                           0.64      1985\n",
      "   macro avg       0.64      0.64      0.63      1985\n",
      "weighted avg       0.64      0.64      0.63      1985\n",
      "\n",
      "\n",
      "5 of kfold 5\n",
      "accuracy_score 0.6357682619647356\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.67      0.53      0.60       997\n",
      "    NEGATIVE       0.61      0.74      0.67       988\n",
      "\n",
      "    accuracy                           0.64      1985\n",
      "   macro avg       0.64      0.64      0.63      1985\n",
      "weighted avg       0.64      0.64      0.63      1985\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "i=1\n",
    "kf = StratifiedKFold(n_splits=5,random_state=1,shuffle=True)\n",
    "for train_index,test_index in kf.split(D,y):\n",
    "     print('\\n{} of kfold {}'.format(i,kf.n_splits))\n",
    "     xtr,xvl = D.loc[train_index],D.loc[test_index]\n",
    "     ytr,yvl = y[train_index],y[test_index]\n",
    "    \n",
    "     model =  LogisticRegression()\n",
    "     model.fit(xtr, ytr)\n",
    "     pred_test = model.predict(xvl)\n",
    "     score = accuracy_score(yvl,pred_test)\n",
    "     print('accuracy_score',score)\n",
    "     target_names = ['POSITIVE','NEGATIVE']\n",
    "     print(classification_report(yvl, pred_test, target_names=target_names))\n",
    "     i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 of kfold 5\n",
      "accuracy_score 0.6513853904282116\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.72      0.50      0.59       996\n",
      "    NEGATIVE       0.61      0.81      0.70       989\n",
      "\n",
      "    accuracy                           0.65      1985\n",
      "   macro avg       0.67      0.65      0.64      1985\n",
      "weighted avg       0.67      0.65      0.64      1985\n",
      "\n",
      "\n",
      "2 of kfold 5\n",
      "accuracy_score 0.6392947103274559\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.71      0.48      0.57       997\n",
      "    NEGATIVE       0.60      0.80      0.69       988\n",
      "\n",
      "    accuracy                           0.64      1985\n",
      "   macro avg       0.65      0.64      0.63      1985\n",
      "weighted avg       0.66      0.64      0.63      1985\n",
      "\n",
      "\n",
      "3 of kfold 5\n",
      "accuracy_score 0.6287153652392947\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.68      0.49      0.57       997\n",
      "    NEGATIVE       0.60      0.76      0.67       988\n",
      "\n",
      "    accuracy                           0.63      1985\n",
      "   macro avg       0.64      0.63      0.62      1985\n",
      "weighted avg       0.64      0.63      0.62      1985\n",
      "\n",
      "\n",
      "4 of kfold 5\n",
      "accuracy_score 0.6372795969773299\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.69      0.50      0.58       997\n",
      "    NEGATIVE       0.61      0.77      0.68       988\n",
      "\n",
      "    accuracy                           0.64      1985\n",
      "   macro avg       0.65      0.64      0.63      1985\n",
      "weighted avg       0.65      0.64      0.63      1985\n",
      "\n",
      "\n",
      "5 of kfold 5\n",
      "accuracy_score 0.636272040302267\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.69      0.50      0.58       997\n",
      "    NEGATIVE       0.61      0.78      0.68       988\n",
      "\n",
      "    accuracy                           0.64      1985\n",
      "   macro avg       0.65      0.64      0.63      1985\n",
      "weighted avg       0.65      0.64      0.63      1985\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "i=1\n",
    "kf = StratifiedKFold(n_splits=5,random_state=1,shuffle=True)\n",
    "for train_index,test_index in kf.split(D,y):\n",
    "     print('\\n{} of kfold {}'.format(i,kf.n_splits))\n",
    "     xtr,xvl = D.loc[train_index],D.loc[test_index]\n",
    "     ytr,yvl = y[train_index],y[test_index]\n",
    "     #sm=SMOTE(random_state=1)\n",
    "     #xtr,ytr=sm.fit_sample(xtr,ytr)\n",
    "     model = BernoulliNB()\n",
    "     model.fit(xtr, ytr)\n",
    "     pred_test = model.predict(xvl)\n",
    "     score = accuracy_score(yvl,pred_test)\n",
    "     print('accuracy_score',score)\n",
    "     target_names = ['POSITIVE','NEGATIVE']\n",
    "     print(classification_report(yvl, pred_test, target_names=target_names))\n",
    "     i+=1 \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 of kfold 5\n",
      "accuracy_score 0.5994962216624685\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.57      0.86      0.68       996\n",
      "    NEGATIVE       0.70      0.34      0.46       989\n",
      "\n",
      "    accuracy                           0.60      1985\n",
      "   macro avg       0.64      0.60      0.57      1985\n",
      "weighted avg       0.64      0.60      0.57      1985\n",
      "\n",
      "\n",
      "2 of kfold 5\n",
      "accuracy_score 0.6438287153652393\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.68      0.54      0.60       997\n",
      "    NEGATIVE       0.62      0.75      0.68       988\n",
      "\n",
      "    accuracy                           0.64      1985\n",
      "   macro avg       0.65      0.64      0.64      1985\n",
      "weighted avg       0.65      0.64      0.64      1985\n",
      "\n",
      "\n",
      "3 of kfold 5\n",
      "accuracy_score 0.6045340050377834\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.72      0.35      0.47       997\n",
      "    NEGATIVE       0.57      0.86      0.69       988\n",
      "\n",
      "    accuracy                           0.60      1985\n",
      "   macro avg       0.64      0.61      0.58      1985\n",
      "weighted avg       0.64      0.60      0.58      1985\n",
      "\n",
      "\n",
      "4 of kfold 5\n",
      "accuracy_score 0.6312342569269521\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.67      0.53      0.59       997\n",
      "    NEGATIVE       0.61      0.73      0.66       988\n",
      "\n",
      "    accuracy                           0.63      1985\n",
      "   macro avg       0.64      0.63      0.63      1985\n",
      "weighted avg       0.64      0.63      0.63      1985\n",
      "\n",
      "\n",
      "5 of kfold 5\n",
      "accuracy_score 0.6292191435768262\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.69      0.48      0.57       997\n",
      "    NEGATIVE       0.60      0.78      0.68       988\n",
      "\n",
      "    accuracy                           0.63      1985\n",
      "   macro avg       0.64      0.63      0.62      1985\n",
      "weighted avg       0.64      0.63      0.62      1985\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "i=1\n",
    "kf = StratifiedKFold(n_splits=5,random_state=1,shuffle=True)\n",
    "for train_index,test_index in kf.split(D,y):\n",
    "     print('\\n{} of kfold {}'.format(i,kf.n_splits))\n",
    "     xtr,xvl = D.loc[train_index],D.loc[test_index]\n",
    "     ytr,yvl = y[train_index],y[test_index]\n",
    "     #sm=SMOTE(random_state=1)\n",
    "     #xtr,ytr=sm.fit_sample(xtr,ytr)\n",
    "     model = SGDClassifier(loss='log',penalty='elasticnet')\n",
    "     model.fit(xtr, ytr)\n",
    "     pred_test = model.predict(xvl)\n",
    "     score = accuracy_score(yvl,pred_test)\n",
    "     print('accuracy_score',score)\n",
    "     target_names = ['POSITIVE','NEGATIVE']\n",
    "     print(classification_report(yvl, pred_test, target_names=target_names))\n",
    "     i+=1\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uni+Bi+Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 of kfold 5\n",
      "accuracy_score 0.7395465994962217\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.75      0.73      0.74       996\n",
      "    NEGATIVE       0.73      0.75      0.74       989\n",
      "\n",
      "    accuracy                           0.74      1985\n",
      "   macro avg       0.74      0.74      0.74      1985\n",
      "weighted avg       0.74      0.74      0.74      1985\n",
      "\n",
      "\n",
      "2 of kfold 5\n",
      "accuracy_score 0.7269521410579345\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.73      0.74      0.73       997\n",
      "    NEGATIVE       0.73      0.72      0.72       988\n",
      "\n",
      "    accuracy                           0.73      1985\n",
      "   macro avg       0.73      0.73      0.73      1985\n",
      "weighted avg       0.73      0.73      0.73      1985\n",
      "\n",
      "\n",
      "3 of kfold 5\n",
      "accuracy_score 0.7314861460957179\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.73      0.73      0.73       997\n",
      "    NEGATIVE       0.73      0.73      0.73       988\n",
      "\n",
      "    accuracy                           0.73      1985\n",
      "   macro avg       0.73      0.73      0.73      1985\n",
      "weighted avg       0.73      0.73      0.73      1985\n",
      "\n",
      "\n",
      "4 of kfold 5\n",
      "accuracy_score 0.7168765743073048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.73      0.70      0.71       997\n",
      "    NEGATIVE       0.71      0.73      0.72       988\n",
      "\n",
      "    accuracy                           0.72      1985\n",
      "   macro avg       0.72      0.72      0.72      1985\n",
      "weighted avg       0.72      0.72      0.72      1985\n",
      "\n",
      "\n",
      "5 of kfold 5\n",
      "accuracy_score 0.726448362720403\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.73      0.72      0.72       997\n",
      "    NEGATIVE       0.72      0.74      0.73       988\n",
      "\n",
      "    accuracy                           0.73      1985\n",
      "   macro avg       0.73      0.73      0.73      1985\n",
      "weighted avg       0.73      0.73      0.73      1985\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "i=1\n",
    "kf = StratifiedKFold(n_splits=5,random_state=1,shuffle=True)\n",
    "for train_index,test_index in kf.split(E,y):\n",
    "     print('\\n{} of kfold {}'.format(i,kf.n_splits))\n",
    "     xtr,xvl = E.loc[train_index],E.loc[test_index]\n",
    "     ytr,yvl = y[train_index],y[test_index]\n",
    "    \n",
    "     model =  LogisticRegression()\n",
    "     model.fit(xtr, ytr)\n",
    "     pred_test = model.predict(xvl)\n",
    "     score = accuracy_score(yvl,pred_test)\n",
    "     print('accuracy_score',score)\n",
    "     target_names = ['POSITIVE','NEGATIVE']\n",
    "     print(classification_report(yvl, pred_test, target_names=target_names))\n",
    "     i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 of kfold 5\n",
      "accuracy_score 0.7229219143576826\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.77      0.64      0.70       996\n",
      "    NEGATIVE       0.69      0.81      0.74       989\n",
      "\n",
      "    accuracy                           0.72      1985\n",
      "   macro avg       0.73      0.72      0.72      1985\n",
      "weighted avg       0.73      0.72      0.72      1985\n",
      "\n",
      "\n",
      "2 of kfold 5\n",
      "accuracy_score 0.691183879093199\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.73      0.61      0.67       997\n",
      "    NEGATIVE       0.66      0.77      0.71       988\n",
      "\n",
      "    accuracy                           0.69      1985\n",
      "   macro avg       0.70      0.69      0.69      1985\n",
      "weighted avg       0.70      0.69      0.69      1985\n",
      "\n",
      "\n",
      "3 of kfold 5\n",
      "accuracy_score 0.7002518891687658\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.73      0.63      0.68       997\n",
      "    NEGATIVE       0.68      0.77      0.72       988\n",
      "\n",
      "    accuracy                           0.70      1985\n",
      "   macro avg       0.70      0.70      0.70      1985\n",
      "weighted avg       0.70      0.70      0.70      1985\n",
      "\n",
      "\n",
      "4 of kfold 5\n",
      "accuracy_score 0.6846347607052897\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.72      0.62      0.66       997\n",
      "    NEGATIVE       0.66      0.75      0.70       988\n",
      "\n",
      "    accuracy                           0.68      1985\n",
      "   macro avg       0.69      0.68      0.68      1985\n",
      "weighted avg       0.69      0.68      0.68      1985\n",
      "\n",
      "\n",
      "5 of kfold 5\n",
      "accuracy_score 0.705793450881612\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.75      0.62      0.68       997\n",
      "    NEGATIVE       0.67      0.79      0.73       988\n",
      "\n",
      "    accuracy                           0.71      1985\n",
      "   macro avg       0.71      0.71      0.70      1985\n",
      "weighted avg       0.71      0.71      0.70      1985\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "i=1\n",
    "kf = StratifiedKFold(n_splits=5,random_state=1,shuffle=True)\n",
    "for train_index,test_index in kf.split(E,y):\n",
    "     print('\\n{} of kfold {}'.format(i,kf.n_splits))\n",
    "     xtr,xvl = E.loc[train_index],E.loc[test_index]\n",
    "     ytr,yvl = y[train_index],y[test_index]\n",
    "     #sm=SMOTE(random_state=1)\n",
    "     #xtr,ytr=sm.fit_sample(xtr,ytr)\n",
    "     model = BernoulliNB()\n",
    "     model.fit(xtr, ytr)\n",
    "     pred_test = model.predict(xvl)\n",
    "     score = accuracy_score(yvl,pred_test)\n",
    "     print('accuracy_score',score)\n",
    "     target_names = ['POSITIVE','NEGATIVE']\n",
    "     print(classification_report(yvl, pred_test, target_names=target_names))\n",
    "     i+=1 \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 of kfold 5\n",
      "accuracy_score 0.7324937027707809\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.71      0.80      0.75       996\n",
      "    NEGATIVE       0.77      0.67      0.71       989\n",
      "\n",
      "    accuracy                           0.73      1985\n",
      "   macro avg       0.74      0.73      0.73      1985\n",
      "weighted avg       0.74      0.73      0.73      1985\n",
      "\n",
      "\n",
      "2 of kfold 5\n",
      "accuracy_score 0.7274559193954659\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.76      0.68      0.71       997\n",
      "    NEGATIVE       0.70      0.78      0.74       988\n",
      "\n",
      "    accuracy                           0.73      1985\n",
      "   macro avg       0.73      0.73      0.73      1985\n",
      "weighted avg       0.73      0.73      0.73      1985\n",
      "\n",
      "\n",
      "3 of kfold 5\n",
      "accuracy_score 0.7340050377833753\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.71      0.81      0.75       997\n",
      "    NEGATIVE       0.77      0.66      0.71       988\n",
      "\n",
      "    accuracy                           0.73      1985\n",
      "   macro avg       0.74      0.73      0.73      1985\n",
      "weighted avg       0.74      0.73      0.73      1985\n",
      "\n",
      "\n",
      "4 of kfold 5\n",
      "accuracy_score 0.7214105793450881\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.73      0.72      0.72       997\n",
      "    NEGATIVE       0.72      0.73      0.72       988\n",
      "\n",
      "    accuracy                           0.72      1985\n",
      "   macro avg       0.72      0.72      0.72      1985\n",
      "weighted avg       0.72      0.72      0.72      1985\n",
      "\n",
      "\n",
      "5 of kfold 5\n",
      "accuracy_score 0.7052896725440806\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    POSITIVE       0.78      0.57      0.66       997\n",
      "    NEGATIVE       0.66      0.84      0.74       988\n",
      "\n",
      "    accuracy                           0.71      1985\n",
      "   macro avg       0.72      0.71      0.70      1985\n",
      "weighted avg       0.72      0.71      0.70      1985\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "i=1\n",
    "kf = StratifiedKFold(n_splits=5,random_state=1,shuffle=True)\n",
    "for train_index,test_index in kf.split(E,y):\n",
    "     print('\\n{} of kfold {}'.format(i,kf.n_splits))\n",
    "     xtr,xvl = E.loc[train_index],E.loc[test_index]\n",
    "     ytr,yvl = y[train_index],y[test_index]\n",
    "     #sm=SMOTE(random_state=1)\n",
    "     #xtr,ytr=sm.fit_sample(xtr,ytr)\n",
    "     model = SGDClassifier(loss='log',penalty='elasticnet')\n",
    "     model.fit(xtr, ytr)\n",
    "     pred_test = model.predict(xvl)\n",
    "     score = accuracy_score(yvl,pred_test)\n",
    "     print('accuracy_score',score)\n",
    "     target_names = ['POSITIVE','NEGATIVE']\n",
    "     print(classification_report(yvl, pred_test, target_names=target_names))\n",
    "     i+=1\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
